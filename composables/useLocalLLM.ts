// composables/useLocalLLM.ts
import { computed } from "vue"; 
import { useState } from "#app"; 

// ðŸš¨ å¤‰æ›´ç‚¹1: ã‚¨ãƒ³ã‚¸ãƒ³æœ¬ä½“ã¯ãƒªã‚¢ã‚¯ãƒ†ã‚£ãƒ–ç®¡ç†å¤–ã®ã€ŒãŸã ã®å¤‰æ•°ã€ã«ã™ã‚‹
// ã“ã‚Œã«ã‚ˆã‚Šã€Vueã®ProxyåŒ–(ãƒ©ãƒƒãƒ—)ã‚’å›žé¿ã—ã€WASMã¨ã®BindingErrorã‚’é˜²ã
let _globalEngineInstance: any = null;

// ã‚¹ãƒˆã‚¢ã¯ã€ŒçŠ¶æ…‹ï¼ˆãƒ•ãƒ©ã‚°ã‚„ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã€ã ã‘ã‚’ç®¡ç†ã™ã‚‹
interface LLMStore {
    // engine: any; // å‰Šé™¤
    isInitializing: boolean;
    isReady: boolean;
    status: string;
}

export const useLLMGlobalStore = () => useState<LLMStore>('llmStore', () => ({
    // engine: null, // å‰Šé™¤
    isInitializing: false,
    isReady: false,
    status: "æœªåˆæœŸåŒ–",
}));

// å¤–éƒ¨ï¼ˆãƒ—ãƒ©ã‚°ã‚¤ãƒ³ï¼‰ã‹ã‚‰ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ã‚»ãƒƒãƒˆã™ã‚‹ãŸã‚ã®ã‚»ãƒƒã‚¿ãƒ¼é–¢æ•°ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
export const setGlobalEngine = (instance: any) => {
    _globalEngineInstance = instance;
};

// å¤–éƒ¨ã‹ã‚‰ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ã‚²ãƒƒã‚¿ãƒ¼ï¼ˆç›´æŽ¥å‚ç…§ç”¨ï¼‰
export const getGlobalEngine = () => {
    return _globalEngineInstance;
};


export default function useLocalLLM() {
  
  const store = useLLMGlobalStore();
  
  const initialize = () => {
    console.warn("åˆæœŸåŒ–ã¯Pluginã§è¡Œã‚ã‚Œã¾ã™ã€‚");
  };

  const disposeEngine = async () => {
    // ãƒªã‚¢ã‚¯ãƒ†ã‚£ãƒ–å¤‰æ•°ã§ã¯ãªãã€ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’å‚ç…§
    const engine = _globalEngineInstance; 
    
    if (engine && typeof engine.dispose === 'function') {
        try {
            store.value.status = "ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ç ´æ£„ä¸­...";
            await engine.dispose(); 
            
            // å¤‰æ•°ã‚’nullã«æˆ»ã™
            _globalEngineInstance = null;
            
            store.value.isReady = false;
            store.value.isInitializing = false;
            store.value.status = "ã‚¨ãƒ³ã‚¸ãƒ³ã¯æ­£å¸¸ã«ç ´æ£„ã•ã‚Œã¾ã—ãŸã€‚";
            console.log("[WebLLM] Engine disposed successfully.");
        } catch (e) {
            console.error("[WebLLM] ç ´æ£„ã‚¨ãƒ©ãƒ¼:", e);
        }
    }
  };

  const resetChat = async () => {
      console.warn("[WebLLM Reset] å¼·åˆ¶ãƒªã‚»ãƒƒãƒˆ");
      await disposeEngine(); 
      store.value.isReady = false;
      store.value.status = "ãƒªã‚»ãƒƒãƒˆå®Œäº†ã€‚ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"; 
  };

  const generateStream = async (prompt: string, onChunk: (t: string) => void) => {
    // ãƒªã‚¢ã‚¯ãƒ†ã‚£ãƒ–å¤‰æ•°ã§ã¯ãªãã€ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’å‚ç…§
    const engine = _globalEngineInstance; 
    
    if (!engine) {
        throw new Error("Engine ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚");
    }

    try {
      console.log("[WebLLM] Generating stream...", prompt);
      
      const stream = await engine.chat.completions.create({
        messages: [{ role: "user", content: prompt }],
        stream: true, 
        temperature: 0.7,
        max_tokens: 512,
      });

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || "";
        if (content) {
            onChunk(content);
        }
      }

    } catch (err) {
      console.error("[WebLLM Generation Error]", err);
      throw err;
    }
  };

  return {
    initialize, 
    generateStream,
    resetChat,
    disposeEngine,
    // ã‚¹ãƒˆã‚¢ã®çŠ¶æ…‹ã ã‘ã‚’è¿”ã™
    isReady: computed(() => store.value.isReady),
    isLoading: computed(() => store.value.isInitializing),
    status: computed(() => store.value.status),
  };
}