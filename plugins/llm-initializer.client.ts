// plugins/llm-initializer.client.ts

import { defineNuxtPlugin } from '#app';
// setGlobalEngine ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«è¿½åŠ 
import { useLLMGlobalStore, setGlobalEngine } from '~/composables/useLocalLLM'; 
// ğŸš¨ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†ã¸ç§»è¡Œ (@mlc-ai/web-llm ã‚’ npm install ã—ã¦ã„ã‚‹å‰æ)
import * as webllm from '@mlc-ai/web-llm'; 

let hasLLMInitialized = false; 

export default defineNuxtPlugin(async (nuxtApp) => {
  if (hasLLMInitialized) return;
  
  nuxtApp.hook('app:mounted', async () => {
    if (hasLLMInitialized) return;

    const store = useLLMGlobalStore(); 
    if (store.value.isReady || store.value.isInitializing) return;

    store.value.isInitializing = true;
    store.value.status = "ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ­ãƒ¼ãƒ‰ä¸­...";

    await new Promise(resolve => setTimeout(resolve, 50)); 
    
    // ä»¥å‰ã®CDNã‹ã‚‰ã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯å‰Šé™¤ã—ã€ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨
    const webllmFunctions = webllm.default || webllm;
    const CreateEngine = webllmFunctions.CreateWebWorkerEngine || webllmFunctions.CreateMLCEngine;

    try {
        store.value.status = "ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ä¸­...";
        
        // --- ğŸ¤– LLMãƒ¢ãƒ‡ãƒ«å®šç¾©ã¨å­¦ç¿’ç”¨ãƒ¡ãƒ¢ï¼ˆä¿æŒï¼‰ ---
        // ã“ã‚ŒãŒLLMãƒ¢ãƒ‡ãƒ«å®šç¾©
        // ã“ã“ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã®æ­£å¼åç§°ãŒç¢ºèªã§ãã‚‹
        // https://chat.webllm.ai/
        // 
        // Phi-3-mini: Microsoft ãŒé–‹ç™ºã—ãŸå°å‹ã®LLM
        // Phi-3-mini-4k-instruct-q4f16_1-MLC
        //
        // Llama-3-8B: Meta ãŒé–‹ç™ºã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æœ€æ–°ç‰ˆ
        // Llama-3-8B-Instruct-q4f16_1-MLC 
        //
        // Mistral-7B: ãƒ•ãƒ©ãƒ³ã‚¹ã®Mistral AIãŒé–‹ç™ºã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã€ãã®å‡¦ç†ã®é€Ÿã•ã¨ã€ã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹æ€§èƒ½ã®é«˜ã•ãŒç‰¹å¾´
        // Mistral-7B-Instruct-v0.2-q4f16_1-MLC
        //
        // Gemma-2B: GoogleãŒé–‹ç™ºã—ãŸè»½é‡ãƒ¢ãƒ‡ãƒ«ã€‚éå¸¸ã«å°ã•ã„20å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å‹•ä½œã—ã€ç‰¹ã«æ¨è«–é€Ÿåº¦ãŒé€Ÿã„
        // æ—¥æœ¬èªç‰¹åŒ–ã§å®‰å®šã—ã¦ã„ãŸ: gemma-2-2b-jpn-it-q4f16_1-MLC
        const LOCAL_LLM = "gemma-2-2b-jpn-it-q4f16_1-MLC";
        // ---------------------------------------------

        // ä»¥å‰ã® Wasm_URL_Base ã®å®šç¾©ï¼ˆCDNç”¨ï¼‰ã¯ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç§»è¡Œã®ãŸã‚å‰Šé™¤
        
        const engineInstance = await CreateEngine(LOCAL_LLM, {
            initProgressCallback: (progress: { text: string }) => {
                store.value.status = progress.text;
            },
            // WASMãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã¯ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã¯WebLLMå´ãŒè‡ªå‹•ã§è§£æ±ºã™ã‚‹ãŸã‚ã€
            // wasmUrlInWorker / wasmUrl ã®æŒ‡å®šã¯å‰Šé™¤ã—ã¾ã—ãŸã€‚
        });

        // ğŸš¨ ã€ã“ã“ãŒä¿®æ­£ç‚¹ã€‘ ğŸš¨
        // store.value.engine = engineInstance; // â† ã“ã‚Œã‚’ã‚„ã‚ã‚‹ï¼ˆProxyåŒ–ã•ã‚Œã‚‹ã‹ã‚‰ï¼‰
        // å‹æƒ…å ±ã‚’æŒ‡å®šã—ã€ç”Ÿã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å¤‰æ•°ã«ä¿å­˜
        setGlobalEngine(engineInstance as webllm.ChatModule);      
        
        store.value.status = "ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†";
        store.value.isReady = true;
        hasLLMInitialized = true;
        
    } catch (err) {
        console.error(err);
        store.value.status = "åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼";
    } finally {
        store.value.isInitializing = false; 
    }
  });
});