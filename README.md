# mini_ai

Nuxtアプリで、ローカルLLM（WebLLM）の実装を行なったサンプルプロジェクト。

この実装を参考に他のプロジェクトにAIを導入していく。

## モデルの切り替え

plugins/llm-initializer.client.ts で行える。

## モデルの用語

モデル名には`q4f16_1`のような名前がついている。

q0: 高クオリティ。意味: 量子化（圧縮）を最小限に抑えており、モデルが持つ情報量が多く、回答精度が最も高いです。その代わり、VRAM消費とファイルサイズは大きくなります。

q4: 圧縮によるやや劣化。重みを4ビットに圧縮しています。ファイルサイズとVRAM消費が最小になり、推論速度も速くなります。しかし、圧縮の過程で情報の一部を削るため、精度はq0に比べてわずかに落ちる可能性があります。

スマホのことを考えると、`q4f16_1`がベストと思われる。